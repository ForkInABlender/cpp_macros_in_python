# Dylan Kenneth Eliot & GPT-4-plugins (Alpha edition)


"""

This file was regenerated by GPT so it worked similar to how c++ macros work. Now one can string together the result, and then execute it.
 Now if done to imitate compiled c/c++ code, one might be able to create a 1:1 equally optimized result that could do a bit more control.

Now yes, this does leave more room for mapping of functionality beyond pre-processor. This meaning one would have to also configure the script so it
 kept track of each keyword for pre-mapping it per OS, then having it keyword to logically mapped python functionality or vise versa. Or even a a way
  to map from one language to the next. Maybe even a inter-language script interpreter.

In the way of java, c++, rust, and the like, I'd rather not have to compile my code, but it just run. Mainly because the more compiled it is, the harder
 it becomes to debug.

So instead, why not compile the least, use keystone and the AssemblerFunction() with ctypes & mmap, and do similar annotation mapping and response coding?
 And why not in addition "annotate then REPL" that same code? It would likely same time and energy. Especially if all you have to do is read, follow, 
  evaluate, and print in a loop til end of program. Instead of complex compile steps for each OS type uniquely for it to run. While compiling it is at a
 level needed, compiling everything down for efficiency also has its limits in the complexity it was meant to illiminate.

But if you only have to worry about logic needed to run, then the better. Especially if it is almost a 1:1 by even macro and other keyword mappings.
 Similar can be done c++'s goto and label mechanry, as well as mimick switch & case with with-while statement assertions during execution. What it gives
  is the option to not compile but thuroughly hammer out what should imitate c++ execution for your OS(/es) and CPU architecture types. Or, say, all types
 of c++ as long as you have an annotation for when you switch between c++ annotation macro types. Then you could worry about macros for switching assembly
  used. And using unicorn-engine, one might be able to make use of c++ and assembly such that it should work when templated to python code. However, this
 does invariably also mean you'd need to hand code your kernels and their corresponding interrupt, responses, etcetera.
 
"""

class Preprocessor:
		def __init__(self):
				self.macros = {}

		def define_macro(self, macro, value):
				self.macros[macro] = ' '.join(value)

		def undef_macro(self, macro):
				if macro in self.macros:
						del self.macros[macro]

		def ifdef_macro(self, macro):
				return macro in self.macros

		def elif_macro(self, macro, value):
				return macro in self.macros and self.macros[macro] == ' '.join(value)

		def include_macro(self, file_path):
				with open(file_path, 'r') as f:
						return f.readlines()

		def pragma_macro(self, command):
				# Add implementation for #pragma directive
				pass

		def process_directive(self, line):
				directive = line.split()[0]
				if directive == "#define":
						macro, value = line.split()[1], line.split()[2:]
						self.define_macro(macro, value)
				elif directive == "#undef":
						macro = line.split()[1]
						self.undef_macro(macro)
				elif directive == "#pragma":
						command = line.split()[1:]
						self.pragma_macro(command)
				elif directive == "#include":
						file_path = line.split()[1].strip('"')
						return self.include_macro(file_path)

		def preprocess(self, code):
				processed_code = []
				skip = False
				for line in code:
						if line.startswith("#"):
								directive = line.split()[0]

								if directive == "#include":
										included_code = self.process_directive(line)
										processed_code.extend(self.preprocess(included_code))
										continue

								self.process_directive(line)

								if directive == "#ifdef":
										macro = line.split()[1]
										skip = not self.ifdef_macro(macro)
								elif directive == "#elif":
										macro, value = line.split()[1], line.split()[2:]
										skip = not self.elif_macro(macro, value)
								elif directive == "#else":
										skip = not skip
								elif directive == "#endif":
										skip = False
						elif not skip:
								processed_code.append(line)
				return processed_code

# Example usage
code = [
		'#include "some_file.py"',  # Make sure this file exists
		"#define MAX_VAL 10",
		"#ifdef MAX_VAL",
		"print('MAX_VAL is defined')",
		"#elif MAX_VAL > 5",
		"print('MAX_VAL is greater than 5')",
		"#else",
		"print('MAX_VAL is less than or equal to 5')",
		"#endif"
]

preprocessor = Preprocessor()
processed_code = preprocessor.preprocess(code)
print('\n'.join(processed_code))
